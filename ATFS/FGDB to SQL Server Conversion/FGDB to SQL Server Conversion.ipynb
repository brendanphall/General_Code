{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"initial_id\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": true\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"Windows FGDB to SQL Server Converter\\n\",\n",
    "    \"Optimized for Windows environment with direct SQL Server access\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"import geopandas as gpd\\n\",\n",
    "    \"import fiona\\n\",\n",
    "    \"import pyodbc\\n\",\n",
    "    \"from sqlalchemy import create_engine, text\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"\\n\",\n",
    "    \"class WindowsFGDBConverter:\\n\",\n",
    "    \"    def __init__(self, server, database, fgdb_path):\\n\",\n",
    "    \"        self.server = server\\n\",\n",
    "    \"        self.database = database\\n\",\n",
    "    \"        self.fgdb_path = fgdb_path\\n\",\n",
    "    \"        self.engine = None\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def create_connection(self):\\n\",\n",
    "    \"        \\\"\\\"\\\"Create SQL Server connection using Windows authentication\\\"\\\"\\\"\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            # SQLAlchemy connection string for Windows auth\\n\",\n",
    "    \"            connection_string = f\\\"mssql+pyodbc://@{self.server}/{self.database}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"            self.engine = create_engine(connection_string, fast_executemany=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Test connection\\n\",\n",
    "    \"            with self.engine.connect() as conn:\\n\",\n",
    "    \"                result = conn.execute(text(\\\"SELECT @@VERSION\\\"))\\n\",\n",
    "    \"                version = result.fetchone()[0]\\n\",\n",
    "    \"                print(f\\\"‚úÖ Connected to SQL Server\\\")\\n\",\n",
    "    \"                print(f\\\"   Version: {version[:60]}...\\\")\\n\",\n",
    "    \"                return True\\n\",\n",
    "    \"\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            print(f\\\"‚ùå Connection failed: {e}\\\")\\n\",\n",
    "    \"            return False\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def list_fgdb_layers(self):\\n\",\n",
    "    \"        \\\"\\\"\\\"List all layers in the FGDB\\\"\\\"\\\"\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            if not os.path.exists(self.fgdb_path):\\n\",\n",
    "    \"                print(f\\\"‚ùå FGDB not found: {self.fgdb_path}\\\")\\n\",\n",
    "    \"                return []\\n\",\n",
    "    \"\\n\",\n",
    "    \"            layers = fiona.listlayers(self.fgdb_path)\\n\",\n",
    "    \"            print(f\\\"üìã Found {len(layers)} layers in FGDB:\\\")\\n\",\n",
    "    \"            for i, layer in enumerate(layers, 1):\\n\",\n",
    "    \"                print(f\\\"   {i}. {layer}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"            return layers\\n\",\n",
    "    \"\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            print(f\\\"‚ùå Error listing FGDB layers: {e}\\\")\\n\",\n",
    "    \"            return []\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def get_layer_preview(self, layer_name, sample_size=5):\\n\",\n",
    "    \"        \\\"\\\"\\\"Get a preview of the layer data\\\"\\\"\\\"\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            gdf = gpd.read_file(self.fgdb_path, layer=layer_name, rows=sample_size)\\n\",\n",
    "    \"\\n\",\n",
    "    \"            info = {\\n\",\n",
    "    \"                'total_features': len(gpd.read_file(self.fgdb_path, layer=layer_name, rows=1000).index),  # Quick count\\n\",\n",
    "    \"                'geometry_type': gdf.geometry.geom_type.mode().iloc[0] if len(gdf) > 0 else 'Unknown',\\n\",\n",
    "    \"                'columns': list(gdf.columns),\\n\",\n",
    "    \"                'crs': gdf.crs.to_string() if gdf.crs else 'Unknown',\\n\",\n",
    "    \"                'bounds': gdf.total_bounds if len(gdf) > 0 else None\\n\",\n",
    "    \"            }\\n\",\n",
    "    \"\\n\",\n",
    "    \"            return info, gdf.head(sample_size)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            print(f\\\"   ‚ö†Ô∏è Error getting preview: {e}\\\")\\n\",\n",
    "    \"            return None, None\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def clean_column_names(self, columns):\\n\",\n",
    "    \"        \\\"\\\"\\\"Clean column names for SQL Server compatibility\\\"\\\"\\\"\\n\",\n",
    "    \"        cleaned = []\\n\",\n",
    "    \"        for col in columns:\\n\",\n",
    "    \"            # Replace problematic characters\\n\",\n",
    "    \"            clean_col = col.replace(' ', '_').replace('-', '_').replace('.', '_')\\n\",\n",
    "    \"            clean_col = clean_col.replace('(', '').replace(')', '')\\n\",\n",
    "    \"            clean_col = clean_col.replace('#', 'num').replace('%', 'pct')\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Ensure it starts with a letter\\n\",\n",
    "    \"            if clean_col[0].isdigit():\\n\",\n",
    "    \"                clean_col = f\\\"col_{clean_col}\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Limit length\\n\",\n",
    "    \"            if len(clean_col) > 50:\\n\",\n",
    "    \"                clean_col = clean_col[:50]\\n\",\n",
    "    \"\\n\",\n",
    "    \"            cleaned.append(clean_col)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        return cleaned\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def determine_sql_types(self, gdf):\\n\",\n",
    "    \"        \\\"\\\"\\\"Determine appropriate SQL Server data types\\\"\\\"\\\"\\n\",\n",
    "    \"        dtype_mapping = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"        for col in gdf.columns:\\n\",\n",
    "    \"            if col == 'geometry':\\n\",\n",
    "    \"                continue\\n\",\n",
    "    \"\\n\",\n",
    "    \"            if gdf[col].dtype == 'object':\\n\",\n",
    "    \"                # String column - check max length\\n\",\n",
    "    \"                max_len = gdf[col].astype(str).str.len().max()\\n\",\n",
    "    \"                if pd.isna(max_len) or max_len == 0:\\n\",\n",
    "    \"                    dtype_mapping[col] = 'NVARCHAR(100)'\\n\",\n",
    "    \"                elif max_len > 4000:\\n\",\n",
    "    \"                    dtype_mapping[col] = 'TEXT'\\n\",\n",
    "    \"                else:\\n\",\n",
    "    \"                    dtype_mapping[col] = f'NVARCHAR({min(int(max_len * 1.5), 4000)})'\\n\",\n",
    "    \"\\n\",\n",
    "    \"            elif gdf[col].dtype in ['int64', 'int32', 'int16']:\\n\",\n",
    "    \"                dtype_mapping[col] = 'INTEGER'\\n\",\n",
    "    \"\\n\",\n",
    "    \"            elif gdf[col].dtype in ['float64', 'float32']:\\n\",\n",
    "    \"                dtype_mapping[col] = 'FLOAT'\\n\",\n",
    "    \"\\n\",\n",
    "    \"            elif gdf[col].dtype == 'bool':\\n\",\n",
    "    \"                dtype_mapping[col] = 'BIT'\\n\",\n",
    "    \"\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                dtype_mapping[col] = 'NVARCHAR(255)'  # Default\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Add geometry column\\n\",\n",
    "    \"        dtype_mapping['Shape'] = 'GEOMETRY'\\n\",\n",
    "    \"\\n\",\n",
    "    \"        return dtype_mapping\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def convert_layer(self, layer_name, chunk_size=1000):\\n\",\n",
    "    \"        \\\"\\\"\\\"Convert a single layer from FGDB to SQL Server\\\"\\\"\\\"\\n\",\n",
    "    \"        print(f\\\"\\\\nüîÑ Converting layer: {layer_name}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            # Get layer preview\\n\",\n",
    "    \"            info, preview = self.get_layer_preview(layer_name)\\n\",\n",
    "    \"            if info:\\n\",\n",
    "    \"                print(f\\\"   üìä Features: ~{info['total_features']}\\\")\\n\",\n",
    "    \"                print(f\\\"   üó∫Ô∏è Geometry: {info['geometry_type']}\\\")\\n\",\n",
    "    \"                print(f\\\"   üìã Columns: {len(info['columns'])}\\\")\\n\",\n",
    "    \"                print(f\\\"   üåê CRS: {info['crs']}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Read full layer\\n\",\n",
    "    \"            print(f\\\"   üìñ Reading layer data...\\\")\\n\",\n",
    "    \"            gdf = gpd.read_file(self.fgdb_path, layer=layer_name)\\n\",\n",
    "    \"\\n\",\n",
    "    \"            if len(gdf) == 0:\\n\",\n",
    "    \"                print(f\\\"   ‚ö†Ô∏è Layer is empty, skipping\\\")\\n\",\n",
    "    \"                return True\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Clean column names\\n\",\n",
    "    \"            original_columns = list(gdf.columns)\\n\",\n",
    "    \"            cleaned_columns = self.clean_column_names(original_columns)\\n\",\n",
    "    \"            column_mapping = dict(zip(original_columns, cleaned_columns))\\n\",\n",
    "    \"            gdf = gdf.rename(columns=column_mapping)\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Handle geometry\\n\",\n",
    "    \"            if 'geometry' in gdf.columns:\\n\",\n",
    "    \"                print(f\\\"   üîß Converting geometry to WKT...\\\")\\n\",\n",
    "    \"                gdf['Shape'] = gdf['geometry'].apply(lambda x: x.wkt if x and x.is_valid else None)\\n\",\n",
    "    \"                gdf = gdf.drop('geometry', axis=1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Determine data types\\n\",\n",
    "    \"            dtype_mapping = self.determine_sql_types(gdf)\\n\",\n",
    "    \"\\n\",\n",
    "    \"            print(f\\\"   üíæ Writing {len(gdf)} records to SQL Server...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Drop existing table if it exists\\n\",\n",
    "    \"            with self.engine.connect() as conn:\\n\",\n",
    "    \"                conn.execute(text(f\\\"IF OBJECT_ID('{layer_name}', 'U') IS NOT NULL DROP TABLE {layer_name}\\\"))\\n\",\n",
    "    \"                conn.commit()\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Write data in chunks\\n\",\n",
    "    \"            if len(gdf) > chunk_size:\\n\",\n",
    "    \"                print(f\\\"   üì¶ Writing in chunks of {chunk_size}...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"            gdf.to_sql(\\n\",\n",
    "    \"                name=layer_name,\\n\",\n",
    "    \"                con=self.engine,\\n\",\n",
    "    \"                if_exists='replace',\\n\",\n",
    "    \"                index=False,\\n\",\n",
    "    \"                dtype=dtype_mapping,\\n\",\n",
    "    \"                chunksize=chunk_size,\\n\",\n",
    "    \"                method='multi'\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Create spatial index\\n\",\n",
    "    \"            print(f\\\"   üóÇÔ∏è Creating spatial index...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Calculate bounding box from data\\n\",\n",
    "    \"            if info and info['bounds'] is not None:\\n\",\n",
    "    \"                bounds = info['bounds']\\n\",\n",
    "    \"                buffer = 0.1  # Add small buffer\\n\",\n",
    "    \"                bbox = f\\\"({bounds[0]-buffer}, {bounds[1]-buffer}, {bounds[2]+buffer}, {bounds[3]+buffer})\\\"\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                bbox = \\\"(-180, -90, 180, 90)\\\"  # World extent as fallback\\n\",\n",
    "    \"\\n\",\n",
    "    \"            spatial_index_sql = f\\\"\\\"\\\"\\n\",\n",
    "    \"            CREATE SPATIAL INDEX SIDX_{layer_name}_Shape\\n\",\n",
    "    \"            ON {layer_name}(Shape)\\n\",\n",
    "    \"            USING GEOMETRY_GRID\\n\",\n",
    "    \"            WITH (BOUNDING_BOX = {bbox})\\n\",\n",
    "    \"            \\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"            with self.engine.connect() as conn:\\n\",\n",
    "    \"                conn.execute(text(spatial_index_sql))\\n\",\n",
    "    \"                conn.commit()\\n\",\n",
    "    \"\\n\",\n",
    "    \"            print(f\\\"   ‚úÖ Successfully converted {layer_name}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Show column mapping if names were changed\\n\",\n",
    "    \"            changed_cols = [(orig, new) for orig, new in column_mapping.items() if orig != new and orig != 'geometry']\\n\",\n",
    "    \"            if changed_cols:\\n\",\n",
    "    \"                print(f\\\"   üìù Column name changes:\\\")\\n\",\n",
    "    \"                for orig, new in changed_cols[:5]:  # Show first 5\\n\",\n",
    "    \"                    print(f\\\"      {orig} ‚Üí {new}\\\")\\n\",\n",
    "    \"                if len(changed_cols) > 5:\\n\",\n",
    "    \"                    print(f\\\"      ... and {len(changed_cols) - 5} more\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"            return True\\n\",\n",
    "    \"\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            print(f\\\"   ‚ùå Error converting {layer_name}: {e}\\\")\\n\",\n",
    "    \"            return False\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def convert_all_layers(self, selected_layers=None):\\n\",\n",
    "    \"        \\\"\\\"\\\"Convert all or selected layers\\\"\\\"\\\"\\n\",\n",
    "    \"        print(\\\"üöÄ Starting FGDB to SQL Server conversion\\\")\\n\",\n",
    "    \"        print(f\\\"üìÅ Source: {self.fgdb_path}\\\")\\n\",\n",
    "    \"        print(f\\\"üéØ Target: {self.server} -> {self.database}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Test connection\\n\",\n",
    "    \"        if not self.create_connection():\\n\",\n",
    "    \"            return False\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Get layers\\n\",\n",
    "    \"        available_layers = self.list_fgdb_layers()\\n\",\n",
    "    \"        if not available_layers:\\n\",\n",
    "    \"            return False\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Determine which layers to convert\\n\",\n",
    "    \"        if selected_layers:\\n\",\n",
    "    \"            layers_to_convert = [l for l in selected_layers if l in available_layers]\\n\",\n",
    "    \"            print(f\\\"\\\\nüéØ Converting {len(layers_to_convert)} selected layers\\\")\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            layers_to_convert = available_layers\\n\",\n",
    "    \"            print(f\\\"\\\\nüéØ Converting all {len(layers_to_convert)} layers\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Convert each layer\\n\",\n",
    "    \"        successful = 0\\n\",\n",
    "    \"        failed = 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"        for i, layer in enumerate(layers_to_convert, 1):\\n\",\n",
    "    \"            print(f\\\"\\\\n[{i}/{len(layers_to_convert)}] Processing: {layer}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"            if self.convert_layer(layer):\\n\",\n",
    "    \"                successful += 1\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                failed += 1\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Summary\\n\",\n",
    "    \"        print(f\\\"\\\\nüìä Conversion Summary:\\\")\\n\",\n",
    "    \"        print(f\\\"   ‚úÖ Successful: {successful}\\\")\\n\",\n",
    "    \"        print(f\\\"   ‚ùå Failed: {failed}\\\")\\n\",\n",
    "    \"        print(f\\\"   üìã Total: {len(layers_to_convert)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        if successful > 0:\\n\",\n",
    "    \"            print(f\\\"\\\\nüéâ Conversion complete! You can now query your data:\\\")\\n\",\n",
    "    \"            print(f\\\"   Example: SELECT COUNT(*) FROM {layers_to_convert[0]};\\\")\\n\",\n",
    "    \"            print(f\\\"   Geometry: SELECT Name, Shape.STAsText() FROM {layers_to_convert[0]};\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        return failed == 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"def main():\\n\",\n",
    "    \"    \\\"\\\"\\\"Main function\\\"\\\"\\\"\\n\",\n",
    "    \"    # Configuration - UPDATE THESE VALUES\\n\",\n",
    "    \"    CONFIG = {\\n\",\n",
    "    \"        'server': '100.103.17.32,1433',\\n\",\n",
    "    \"        'database': 'SpatialTest',\\n\",\n",
    "    \"        'fgdb_path': r'D:\\\\arcgis\\\\clients\\\\sample.gdb'  # UPDATE THIS PATH\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"=== Windows FGDB to SQL Server Converter ===\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Validate FGDB path\\n\",\n",
    "    \"    if not os.path.exists(CONFIG['fgdb_path']):\\n\",\n",
    "    \"        print(f\\\"‚ùå FGDB not found: {CONFIG['fgdb_path']}\\\")\\n\",\n",
    "    \"        print(\\\"Please update the fgdb_path in the CONFIG section\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Try to find common locations\\n\",\n",
    "    \"        possible_paths = [\\n\",\n",
    "    \"            r'D:\\\\arcgis\\\\clients',\\n\",\n",
    "    \"            r'C:\\\\arcgis\\\\clients',\\n\",\n",
    "    \"            r'D:\\\\data',\\n\",\n",
    "    \"            r'C:\\\\data'\\n\",\n",
    "    \"        ]\\n\",\n",
    "    \"\\n\",\n",
    "    \"        print(\\\"\\\\nLooking for .gdb files in common locations:\\\")\\n\",\n",
    "    \"        for path in possible_paths:\\n\",\n",
    "    \"            if os.path.exists(path):\\n\",\n",
    "    \"                gdb_files = list(Path(path).glob('*.gdb'))\\n\",\n",
    "    \"                if gdb_files:\\n\",\n",
    "    \"                    print(f\\\"   Found .gdb files in {path}:\\\")\\n\",\n",
    "    \"                    for gdb in gdb_files[:5]:  # Show first 5\\n\",\n",
    "    \"                        print(f\\\"      {gdb}\\\")\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Create converter and run\\n\",\n",
    "    \"    converter = WindowsFGDBConverter(\\n\",\n",
    "    \"        server=CONFIG['server'],\\n\",\n",
    "    \"        database=CONFIG['database'],\\n\",\n",
    "    \"        fgdb_path=CONFIG['fgdb_path']\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Convert all layers\\n\",\n",
    "    \"    success = converter.convert_all_layers()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Or convert specific layers:\\n\",\n",
    "    \"    # success = converter.convert_all_layers(['states', 'fedlandp'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if success:\\n\",\n",
    "    \"        print(\\\"\\\\nüèÜ All conversions completed successfully!\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"\\\\n‚ö†Ô∏è Some conversions failed. Check the output above for details.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if __name__ == \\\"__main__\\\":\\n\",\n",
    "    \"    main()\"\n",
    "   ],\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-07-07T19:44:03.238286Z\",\n",
    "     \"start_time\": \"2025-07-07T19:43:59.596539Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"# FGDB to SQL Server Conversion - Jupyter Notebook Version\\n\",\n",
    "    \"# Cell 1: Test Package Imports\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"=== Testing Python Package Imports ===\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test each package individually\\n\",\n",
    "    \"packages_status = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    import geopandas as gpd\\n\",\n",
    "    \"    print(\\\"‚úÖ geopandas imported successfully\\\")\\n\",\n",
    "    \"    print(f\\\"   Version: {gpd.__version__}\\\")\\n\",\n",
    "    \"    packages_status['geopandas'] = True\\n\",\n",
    "    \"except ImportError as e:\\n\",\n",
    "    \"    print(f\\\"‚ùå geopandas import failed: {e}\\\")\\n\",\n",
    "    \"    packages_status['geopandas'] = False\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    import fiona\\n\",\n",
    "    \"    print(\\\"‚úÖ fiona imported successfully\\\")\\n\",\n",
    "    \"    print(f\\\"   Version: {fiona.__version__}\\\")\\n\",\n",
    "    \"    packages_status['fiona'] = True\\n\",\n",
    "    \"except ImportError as e:\\n\",\n",
    "    \"    print(f\\\"‚ùå fiona import failed: {e}\\\")\\n\",\n",
    "    \"    packages_status['fiona'] = False\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    import pyodbc\\n\",\n",
    "    \"    print(\\\"‚úÖ pyodbc imported successfully\\\")\\n\",\n",
    "    \"    print(f\\\"   Version: {pyodbc.version}\\\")\\n\",\n",
    "    \"    packages_status['pyodbc'] = True\\n\",\n",
    "    \"except ImportError as e:\\n\",\n",
    "    \"    print(f\\\"‚ùå pyodbc import failed: {e}\\\")\\n\",\n",
    "    \"    packages_status['pyodbc'] = False\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    from sqlalchemy import create_engine, __version__ as sqlalchemy_version\\n\",\n",
    "    \"    print(\\\"‚úÖ sqlalchemy imported successfully\\\")\\n\",\n",
    "    \"    print(f\\\"   Version: {sqlalchemy_version}\\\")\\n\",\n",
    "    \"    packages_status['sqlalchemy'] = True\\n\",\n",
    "    \"except ImportError as e:\\n\",\n",
    "    \"    print(f\\\"‚ùå sqlalchemy import failed: {e}\\\")\\n\",\n",
    "    \"    packages_status['sqlalchemy'] = False\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    import pandas as pd\\n\",\n",
    "    \"    print(\\\"‚úÖ pandas imported successfully\\\")\\n\",\n",
    "    \"    print(f\\\"   Version: {pd.__version__}\\\")\\n\",\n",
    "    \"    packages_status['pandas'] = True\\n\",\n",
    "    \"except ImportError as e:\\n\",\n",
    "    \"    print(f\\\"‚ùå pandas import failed: {e}\\\")\\n\",\n",
    "    \"    packages_status['pandas'] = False\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüìä Package Summary:\\\")\\n\",\n",
    "    \"for pkg, status in packages_status.items():\\n\",\n",
    "    \"    status_icon = \\\"‚úÖ\\\" if status else \\\"‚ùå\\\"\\n\",\n",
    "    \"    print(f\\\"   {status_icon} {pkg}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"all_packages_ok = all(packages_status.values())\\n\",\n",
    "    \"print(f\\\"\\\\nüéØ All packages ready: {'Yes' if all_packages_ok else 'No'}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not all_packages_ok:\\n\",\n",
    "    \"    print(\\\"\\\\nüîß To install missing packages, run in a new cell:\\\")\\n\",\n",
    "    \"    print(\\\"!conda install geopandas pyodbc sqlalchemy fiona -c conda-forge -y\\\")\\n\",\n",
    "    \"    print(\\\"# or\\\")\\n\",\n",
    "    \"    print(\\\"!pip install geopandas pyodbc sqlalchemy fiona\\\")\"\n",
    "   ],\n",
    "   \"id\": \"94a16aa01ff8e153\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"=== Testing Python Package Imports ===\\n\",\n",
    "      \"\\n\",\n",
    "      \"‚úÖ geopandas imported successfully\\n\",\n",
    "      \"   Version: 1.1.1\\n\",\n",
    "      \"‚úÖ fiona imported successfully\\n\",\n",
    "      \"   Version: 1.10.1\\n\",\n",
    "      \"‚úÖ pyodbc imported successfully\\n\",\n",
    "      \"   Version: 5.2.0\\n\",\n",
    "      \"‚úÖ sqlalchemy imported successfully\\n\",\n",
    "      \"   Version: 2.0.41\\n\",\n",
    "      \"‚úÖ pandas imported successfully\\n\",\n",
    "      \"   Version: 2.3.1\\n\",\n",
    "      \"\\n\",\n",
    "      \"üìä Package Summary:\\n\",\n",
    "      \"   ‚úÖ geopandas\\n\",\n",
    "      \"   ‚úÖ fiona\\n\",\n",
    "      \"   ‚úÖ pyodbc\\n\",\n",
    "      \"   ‚úÖ sqlalchemy\\n\",\n",
    "      \"   ‚úÖ pandas\\n\",\n",
    "      \"\\n\",\n",
    "      \"üéØ All packages ready: Yes\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 2\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-07-07T19:50:55.001895Z\",\n",
    "     \"start_time\": \"2025-07-07T19:50:54.583489Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"# FGDB to SQL Server Setup Test - PyCharm Version\\n\",\n",
    "    \"# Run this script first to verify everything is working\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"=== FGDB to SQL Server Setup Test ===\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"def test_imports():\\n\",\n",
    "    \"    \\\"\\\"\\\"Test if all required packages work\\\"\\\"\\\"\\n\",\n",
    "    \"    print(\\\"üì¶ Testing package imports...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        import geopandas as gpd\\n\",\n",
    "    \"        print(f\\\"‚úÖ geopandas {gpd.__version__}\\\")\\n\",\n",
    "    \"    except ImportError as e:\\n\",\n",
    "    \"        print(f\\\"‚ùå geopandas failed: {e}\\\")\\n\",\n",
    "    \"        return False\\n\",\n",
    "    \"\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        import fiona\\n\",\n",
    "    \"        print(f\\\"‚úÖ fiona {fiona.__version__}\\\")\\n\",\n",
    "    \"    except ImportError as e:\\n\",\n",
    "    \"        print(f\\\"‚ùå fiona failed: {e}\\\")\\n\",\n",
    "    \"        return False\\n\",\n",
    "    \"\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        import pyodbc\\n\",\n",
    "    \"        print(f\\\"‚úÖ pyodbc {pyodbc.version}\\\")\\n\",\n",
    "    \"    except ImportError as e:\\n\",\n",
    "    \"        print(f\\\"‚ùå pyodbc failed: {e}\\\")\\n\",\n",
    "    \"        return False\\n\",\n",
    "    \"\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        from sqlalchemy import create_engine, __version__ as sqlalchemy_version\\n\",\n",
    "    \"        print(f\\\"‚úÖ sqlalchemy {sqlalchemy_version}\\\")\\n\",\n",
    "    \"    except ImportError as e:\\n\",\n",
    "    \"        print(f\\\"‚ùå sqlalchemy failed: {e}\\\")\\n\",\n",
    "    \"        return False\\n\",\n",
    "    \"\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        import pandas as pd\\n\",\n",
    "    \"        print(f\\\"‚úÖ pandas {pd.__version__}\\\")\\n\",\n",
    "    \"    except ImportError as e:\\n\",\n",
    "    \"        print(f\\\"‚ùå pandas failed: {e}\\\")\\n\",\n",
    "    \"        return False\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return True\\n\",\n",
    "    \"\\n\",\n",
    "    \"def find_fgdb_files():\\n\",\n",
    "    \"    \\\"\\\"\\\"Look for FGDB files in common locations\\\"\\\"\\\"\\n\",\n",
    "    \"    import os\\n\",\n",
    "    \"    from pathlib import Path\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"\\\\nüîç Searching for .gdb files...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    search_paths = [\\n\",\n",
    "    \"        r'D:\\\\arcgis\\\\clients',\\n\",\n",
    "    \"        r'C:\\\\arcgis\\\\clients',\\n\",\n",
    "    \"        r'D:\\\\data',\\n\",\n",
    "    \"        r'C:\\\\data',\\n\",\n",
    "    \"        r'D:\\\\arcgis',\\n\",\n",
    "    \"        r'C:\\\\arcgis'\\n\",\n",
    "    \"    ]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    found_gdbs = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for search_path in search_paths:\\n\",\n",
    "    \"        if os.path.exists(search_path):\\n\",\n",
    "    \"            print(f\\\"   Checking {search_path}...\\\")\\n\",\n",
    "    \"            gdb_files = list(Path(search_path).glob('**/*.gdb'))\\n\",\n",
    "    \"            if gdb_files:\\n\",\n",
    "    \"                print(f\\\"   üìÅ Found {len(gdb_files)} .gdb files:\\\")\\n\",\n",
    "    \"                for gdb in gdb_files[:5]:  # Show first 5\\n\",\n",
    "    \"                    print(f\\\"      {gdb}\\\")\\n\",\n",
    "    \"                    found_gdbs.append(str(gdb))\\n\",\n",
    "    \"                if len(gdb_files) > 5:\\n\",\n",
    "    \"                    print(f\\\"      ... and {len(gdb_files) - 5} more\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if not found_gdbs:\\n\",\n",
    "    \"        print(\\\"   ‚ùå No .gdb files found in common locations\\\")\\n\",\n",
    "    \"        print(\\\"   üí° Try looking in your specific data directories\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return found_gdbs\\n\",\n",
    "    \"\\n\",\n",
    "    \"def test_fgdb_access(fgdb_path):\\n\",\n",
    "    \"    \\\"\\\"\\\"Test access to a specific FGDB\\\"\\\"\\\"\\n\",\n",
    "    \"    import os\\n\",\n",
    "    \"    import fiona\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(f\\\"\\\\nüìÇ Testing FGDB: {fgdb_path}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if not os.path.exists(fgdb_path):\\n\",\n",
    "    \"        print(f\\\"   ‚ùå Path does not exist\\\")\\n\",\n",
    "    \"        return False\\n\",\n",
    "    \"\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        layers = fiona.listlayers(fgdb_path)\\n\",\n",
    "    \"        print(f\\\"   ‚úÖ Accessible - {len(layers)} layers found:\\\")\\n\",\n",
    "    \"        for i, layer in enumerate(layers, 1):\\n\",\n",
    "    \"            print(f\\\"      {i}. {layer}\\\")\\n\",\n",
    "    \"        return layers\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"   ‚ùå Error accessing FGDB: {e}\\\")\\n\",\n",
    "    \"        return False\\n\",\n",
    "    \"\\n\",\n",
    "    \"def test_sql_server():\\n\",\n",
    "    \"    \\\"\\\"\\\"Test SQL Server connection\\\"\\\"\\\"\\n\",\n",
    "    \"    import pyodbc\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(f\\\"\\\\nüîå Testing SQL Server connection...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    server = \\\"100.103.17.32,1433\\\"\\n\",\n",
    "    \"    database = \\\"SpatialTest\\\"\\n\",\n",
    "    \"    username = \\\"dbeaver\\\"\\n\",\n",
    "    \"    password = \\\"dbeaver\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        conn_str = f\\\"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password};\\\"\\n\",\n",
    "    \"        conn = pyodbc.connect(conn_str, timeout=10)\\n\",\n",
    "    \"        cursor = conn.cursor()\\n\",\n",
    "    \"\\n\",\n",
    "    \"        cursor.execute(\\\"SELECT @@VERSION\\\")\\n\",\n",
    "    \"        version = cursor.fetchone()[0]\\n\",\n",
    "    \"        print(f\\\"   ‚úÖ Connected to SQL Server\\\")\\n\",\n",
    "    \"        print(f\\\"   üìä Version: {version[:60]}...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        cursor.execute(\\\"SELECT DB_NAME()\\\")\\n\",\n",
    "    \"        db_name = cursor.fetchone()[0]\\n\",\n",
    "    \"        print(f\\\"   üíæ Database: {db_name}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        conn.close()\\n\",\n",
    "    \"        return True\\n\",\n",
    "    \"\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"   ‚ùå Connection failed: {e}\\\")\\n\",\n",
    "    \"        print(f\\\"   üí° Common issues:\\\")\\n\",\n",
    "    \"        print(f\\\"      - SQL Server not running\\\")\\n\",\n",
    "    \"        print(f\\\"      - Firewall blocking connection\\\")\\n\",\n",
    "    \"        print(f\\\"      - Windows authentication not enabled\\\")\\n\",\n",
    "    \"        return False\\n\",\n",
    "    \"\\n\",\n",
    "    \"def main():\\n\",\n",
    "    \"    \\\"\\\"\\\"Run all tests\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Test 1: Package imports\\n\",\n",
    "    \"    if not test_imports():\\n\",\n",
    "    \"        print(\\\"\\\\n‚ùå Package import test failed!\\\")\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Test 2: Find FGDB files\\n\",\n",
    "    \"    found_gdbs = find_fgdb_files()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Test 3: Test specific FGDB if found\\n\",\n",
    "    \"    if found_gdbs:\\n\",\n",
    "    \"        test_fgdb = found_gdbs[0]  # Test first one found\\n\",\n",
    "    \"        layers = test_fgdb_access(test_fgdb)\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        # Try common test path\\n\",\n",
    "    \"        test_fgdb = r\\\"Z:\\\\Users\\\\brendanhall\\\\GitHub\\\\General_Code\\\\ATFS\\\\FGDB to SQL Server Conversion\\\\esri_ref_data.gdb\\\\esri_ref_data.gdb\\\"\\n\",\n",
    "    \"        layers = test_fgdb_access(test_fgdb)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Test 4: SQL Server connection\\n\",\n",
    "    \"    sql_ok = test_sql_server()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Summary\\n\",\n",
    "    \"    print(f\\\"\\\\n\\\" + \\\"=\\\"*50)\\n\",\n",
    "    \"    print(\\\"üìã TEST SUMMARY\\\")\\n\",\n",
    "    \"    print(\\\"=\\\"*50)\\n\",\n",
    "    \"    print(f\\\"‚úÖ Python packages: Ready\\\")\\n\",\n",
    "    \"    print(f\\\"{'‚úÖ' if found_gdbs or layers else '‚ùå'} FGDB access: {'Ready' if found_gdbs or layers else 'Check paths'}\\\")\\n\",\n",
    "    \"    print(f\\\"{'‚úÖ' if sql_ok else '‚ùå'} SQL Server: {'Ready' if sql_ok else 'Check connection'}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if (found_gdbs or layers) and sql_ok:\\n\",\n",
    "    \"        print(f\\\"\\\\nüéâ ALL TESTS PASSED! Ready for FGDB conversion.\\\")\\n\",\n",
    "    \"        print(f\\\"\\\\nüìù Next steps:\\\")\\n\",\n",
    "    \"        print(f\\\"   1. Update CONFIG in the main script with your FGDB path:\\\")\\n\",\n",
    "    \"        if found_gdbs:\\n\",\n",
    "    \"            print(f\\\"      'fgdb_path': r'{found_gdbs[0]}'\\\")\\n\",\n",
    "    \"        print(f\\\"   2. Run the main conversion script\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(f\\\"\\\\n‚ö†Ô∏è Some tests failed. Please resolve issues before conversion.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if __name__ == \\\"__main__\\\":\\n\",\n",
    "    \"    main()\"\n",
    "   ],\n",
    "   \"id\": \"327643b386812352\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"=== FGDB to SQL Server Setup Test ===\\n\",\n",
    "      \"\\n\",\n",
    "      \"üì¶ Testing package imports...\\n\",\n",
    "      \"‚úÖ geopandas 1.1.1\\n\",\n",
    "      \"‚úÖ fiona 1.10.1\\n\",\n",
    "      \"‚úÖ pyodbc 5.2.0\\n\",\n",
    "      \"‚úÖ sqlalchemy 2.0.41\\n\",\n",
    "      \"‚úÖ pandas 2.3.1\\n\",\n",
    "      \"\\n\",\n",
    "      \"üîç Searching for .gdb files...\\n\",\n",
    "      \"   ‚ùå No .gdb files found in common locations\\n\",\n",
    "      \"   üí° Try looking in your specific data directories\\n\",\n",
    "      \"\\n\",\n",
    "      \"üìÇ Testing FGDB: Z:\\\\Users\\\\brendanhall\\\\GitHub\\\\General_Code\\\\ATFS\\\\FGDB to SQL Server Conversion\\\\esri_ref_data.gdb\\\\esri_ref_data.gdb\\n\",\n",
    "      \"   ‚úÖ Accessible - 4 layers found:\\n\",\n",
    "      \"      1. states\\n\",\n",
    "      \"      2. fedlandp\\n\",\n",
    "      \"      3. park_dtl\\n\",\n",
    "      \"      4. dtl_st\\n\",\n",
    "      \"\\n\",\n",
    "      \"üîå Testing SQL Server connection...\\n\",\n",
    "      \"   ‚úÖ Connected to SQL Server\\n\",\n",
    "      \"   üìä Version: Microsoft SQL Server 2022 (RTM-GDR) (KB5046861) - 16.0.1135....\\n\",\n",
    "      \"   üíæ Database: SpatialTest\\n\",\n",
    "      \"\\n\",\n",
    "      \"==================================================\\n\",\n",
    "      \"üìã TEST SUMMARY\\n\",\n",
    "      \"==================================================\\n\",\n",
    "      \"‚úÖ Python packages: Ready\\n\",\n",
    "      \"‚úÖ FGDB access: Ready\\n\",\n",
    "      \"‚úÖ SQL Server: Ready\\n\",\n",
    "      \"\\n\",\n",
    "      \"üéâ ALL TESTS PASSED! Ready for FGDB conversion.\\n\",\n",
    "      \"\\n\",\n",
    "      \"üìù Next steps:\\n\",\n",
    "      \"   1. Update CONFIG in the main script with your FGDB path:\\n\",\n",
    "      \"   2. Run the main conversion script\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 6\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-07-07T19:44:35.876209Z\",\n",
    "     \"start_time\": \"2025-07-07T19:44:34.776637Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": \"\",\n",
    "   \"id\": \"7260ca032cec1854\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"=== FGDB to SQL Server Setup Test ===\\n\",\n",
    "      \"\\n\",\n",
    "      \"üì¶ Testing package imports...\\n\",\n",
    "      \"‚úÖ geopandas 1.1.1\\n\",\n",
    "      \"‚úÖ fiona 1.10.1\\n\",\n",
    "      \"‚úÖ pyodbc 5.2.0\\n\",\n",
    "      \"‚úÖ sqlalchemy 2.0.41\\n\",\n",
    "      \"‚úÖ pandas 2.3.1\\n\",\n",
    "      \"\\n\",\n",
    "      \"üîç Searching for .gdb files...\\n\",\n",
    "      \"   ‚ùå No .gdb files found in common locations\\n\",\n",
    "      \"   üí° Try looking in your specific data directories\\n\",\n",
    "      \"\\n\",\n",
    "      \"üìÇ Testing FGDB: D:\\\\arcgis\\\\clients\\\\sample.gdb\\n\",\n",
    "      \"   ‚ùå Path does not exist\\n\",\n",
    "      \"\\n\",\n",
    "      \"üîå Testing SQL Server connection...\\n\",\n",
    "      \"   ‚ùå Connection failed: ('28000', '[28000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Login failed. The login is from an untrusted domain and cannot be used with Integrated authentication. (18452) (SQLDriverConnect); [28000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Login failed. The login is from an untrusted domain and cannot be used with Integrated authentication. (18452)')\\n\",\n",
    "      \"   üí° Common issues:\\n\",\n",
    "      \"      - SQL Server not running\\n\",\n",
    "      \"      - Firewall blocking connection\\n\",\n",
    "      \"      - Windows authentication not enabled\\n\",\n",
    "      \"\\n\",\n",
    "      \"==================================================\\n\",\n",
    "      \"üìã TEST SUMMARY\\n\",\n",
    "      \"==================================================\\n\",\n",
    "      \"‚úÖ Python packages: Ready\\n\",\n",
    "      \"‚ùå FGDB access: Check paths\\n\",\n",
    "      \"‚ùå SQL Server: Check connection\\n\",\n",
    "      \"\\n\",\n",
    "      \"‚ö†Ô∏è Some tests failed. Please resolve issues before conversion.\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 3\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-07-07T20:07:54.708155Z\",\n",
    "     \"start_time\": \"2025-07-07T20:04:01.337435Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"FGDB to SQL Server Converter - FIXED VERSION\\n\",\n",
    "    \"Complete conversion script for ESRI File Geodatabase to SQL Server\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"import geopandas as gpd\\n\",\n",
    "    \"import fiona\\n\",\n",
    "    \"import pyodbc\\n\",\n",
    "    \"from sqlalchemy import create_engine, text\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# =============================================================================\\n\",\n",
    "    \"# CONFIGURATION - UPDATE THESE VALUES\\n\",\n",
    "    \"# =============================================================================\\n\",\n",
    "    \"\\n\",\n",
    "    \"CONFIG = {\\n\",\n",
    "    \"    'server': '100.103.17.32,1433',\\n\",\n",
    "    \"    'database': 'SpatialTest',\\n\",\n",
    "    \"    'username': 'dbeaver',\\n\",\n",
    "    \"    'password': 'dbeaver',\\n\",\n",
    "    \"    'fgdb_path': r'Z:\\\\Users\\\\brendanhall\\\\GitHub\\\\General_Code\\\\ATFS\\\\FGDB to SQL Server Conversion\\\\esri_ref_data.gdb\\\\esri_ref_data.gdb',\\n\",\n",
    "    \"    'chunk_size': 1000,\\n\",\n",
    "    \"    'selected_layers': None  # None = all layers, or ['layer1', 'layer2'] for specific layers\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"class FGDBConverter:\\n\",\n",
    "    \"    def __init__(self, config):\\n\",\n",
    "    \"        self.config = config\\n\",\n",
    "    \"        self.engine = None\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def log(self, message, level=\\\"INFO\\\"):\\n\",\n",
    "    \"        \\\"\\\"\\\"Simple logging function\\\"\\\"\\\"\\n\",\n",
    "    \"        print(f\\\"[{level}] {message}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def setup_connection(self):\\n\",\n",
    "    \"        \\\"\\\"\\\"Create SQL Server connection\\\"\\\"\\\"\\n\",\n",
    "    \"        self.log(\\\"Setting up SQL Server connection...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            connection_string = (\\n\",\n",
    "    \"                f\\\"mssql+pyodbc://{self.config['username']}:{self.config['password']}\\\"\\n\",\n",
    "    \"                f\\\"@{self.config['server']}/{self.config['database']}\\\"\\n\",\n",
    "    \"                f\\\"?driver=ODBC+Driver+17+for+SQL+Server\\\"\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"\\n\",\n",
    "    \"            self.engine = create_engine(\\n\",\n",
    "    \"                connection_string,\\n\",\n",
    "    \"                fast_executemany=True,\\n\",\n",
    "    \"                pool_pre_ping=True\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Test connection\\n\",\n",
    "    \"            with self.engine.connect() as conn:\\n\",\n",
    "    \"                result = conn.execute(text(\\\"SELECT @@VERSION, DB_NAME()\\\"))\\n\",\n",
    "    \"                version, db_name = result.fetchone()\\n\",\n",
    "    \"                self.log(f\\\"‚úÖ Connected to SQL Server\\\")\\n\",\n",
    "    \"                self.log(f\\\"   Database: {db_name}\\\")\\n\",\n",
    "    \"                self.log(f\\\"   Version: {version[:50]}...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"            return True\\n\",\n",
    "    \"\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            self.log(f\\\"‚ùå Connection failed: {e}\\\", \\\"ERROR\\\")\\n\",\n",
    "    \"            return False\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def get_fgdb_layers(self):\\n\",\n",
    "    \"        \\\"\\\"\\\"Get list of layers in FGDB\\\"\\\"\\\"\\n\",\n",
    "    \"        self.log(f\\\"Reading FGDB: {self.config['fgdb_path']}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        if not os.path.exists(self.config['fgdb_path']):\\n\",\n",
    "    \"            self.log(f\\\"‚ùå FGDB not found: {self.config['fgdb_path']}\\\", \\\"ERROR\\\")\\n\",\n",
    "    \"            return []\\n\",\n",
    "    \"\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            layers = fiona.listlayers(self.config['fgdb_path'])\\n\",\n",
    "    \"            self.log(f\\\"‚úÖ Found {len(layers)} layers: {', '.join(layers)}\\\")\\n\",\n",
    "    \"            return layers\\n\",\n",
    "    \"\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            self.log(f\\\"‚ùå Error reading FGDB: {e}\\\", \\\"ERROR\\\")\\n\",\n",
    "    \"            return []\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def clean_column_names(self, columns):\\n\",\n",
    "    \"        \\\"\\\"\\\"Clean column names for SQL Server compatibility\\\"\\\"\\\"\\n\",\n",
    "    \"        cleaned = []\\n\",\n",
    "    \"        for col in columns:\\n\",\n",
    "    \"            # Replace problematic characters\\n\",\n",
    "    \"            clean_col = col.replace(' ', '_').replace('-', '_').replace('.', '_')\\n\",\n",
    "    \"            clean_col = clean_col.replace('(', '').replace(')', '')\\n\",\n",
    "    \"            clean_col = clean_col.replace('#', 'num').replace('%', 'pct')\\n\",\n",
    "    \"            clean_col = clean_col.replace('/', '_').replace('\\\\\\\\', '_')\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Ensure starts with letter\\n\",\n",
    "    \"            if clean_col and clean_col[0].isdigit():\\n\",\n",
    "    \"                clean_col = f\\\"col_{clean_col}\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Limit length\\n\",\n",
    "    \"            if len(clean_col) > 50:\\n\",\n",
    "    \"                clean_col = clean_col[:50]\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Handle empty names\\n\",\n",
    "    \"            if not clean_col:\\n\",\n",
    "    \"                clean_col = f\\\"col_{len(cleaned)}\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"            cleaned.append(clean_col)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        return cleaned\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def convert_layer(self, layer_name):\\n\",\n",
    "    \"        \\\"\\\"\\\"FIXED: Simplified conversion that lets pandas handle data types\\\"\\\"\\\"\\n\",\n",
    "    \"        self.log(f\\\"\\\\nüîÑ Converting layer: {layer_name}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            # Read the data\\n\",\n",
    "    \"            gdf = gpd.read_file(self.config['fgdb_path'], layer=layer_name)\\n\",\n",
    "    \"\\n\",\n",
    "    \"            if len(gdf) == 0:\\n\",\n",
    "    \"                self.log(f\\\"   ‚ö†Ô∏è Layer is empty, skipping\\\")\\n\",\n",
    "    \"                return True\\n\",\n",
    "    \"\\n\",\n",
    "    \"            self.log(f\\\"   üìä Processing {len(gdf)} features\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Show geometry info\\n\",\n",
    "    \"            if 'geometry' in gdf.columns and len(gdf) > 0:\\n\",\n",
    "    \"                geom_types = gdf.geometry.geom_type.value_counts()\\n\",\n",
    "    \"                self.log(f\\\"   üó∫Ô∏è Geometry types: {dict(geom_types)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Clean column names\\n\",\n",
    "    \"            original_columns = list(gdf.columns)\\n\",\n",
    "    \"            cleaned_columns = self.clean_column_names(original_columns)\\n\",\n",
    "    \"            column_mapping = dict(zip(original_columns, cleaned_columns))\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Handle duplicate column names\\n\",\n",
    "    \"            if len(set(cleaned_columns)) != len(cleaned_columns):\\n\",\n",
    "    \"                self.log(f\\\"   ‚ö†Ô∏è Warning: Duplicate column names after cleaning\\\", \\\"WARN\\\")\\n\",\n",
    "    \"                seen = set()\\n\",\n",
    "    \"                unique_cleaned = []\\n\",\n",
    "    \"                for col in cleaned_columns:\\n\",\n",
    "    \"                    if col in seen:\\n\",\n",
    "    \"                        counter = 1\\n\",\n",
    "    \"                        new_col = f\\\"{col}_{counter}\\\"\\n\",\n",
    "    \"                        while new_col in seen:\\n\",\n",
    "    \"                            counter += 1\\n\",\n",
    "    \"                            new_col = f\\\"{col}_{counter}\\\"\\n\",\n",
    "    \"                        unique_cleaned.append(new_col)\\n\",\n",
    "    \"                        seen.add(new_col)\\n\",\n",
    "    \"                    else:\\n\",\n",
    "    \"                        unique_cleaned.append(col)\\n\",\n",
    "    \"                        seen.add(col)\\n\",\n",
    "    \"                cleaned_columns = unique_cleaned\\n\",\n",
    "    \"                column_mapping = dict(zip(original_columns, cleaned_columns))\\n\",\n",
    "    \"\\n\",\n",
    "    \"            gdf = gdf.rename(columns=column_mapping)\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Handle geometry\\n\",\n",
    "    \"            has_geometry = False\\n\",\n",
    "    \"            if 'geometry' in gdf.columns:\\n\",\n",
    "    \"                self.log(f\\\"   üîß Converting geometry to WKT...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"                def safe_wkt(geom):\\n\",\n",
    "    \"                    try:\\n\",\n",
    "    \"                        if geom is None or geom.is_empty:\\n\",\n",
    "    \"                            return None\\n\",\n",
    "    \"                        if not geom.is_valid:\\n\",\n",
    "    \"                            geom = geom.buffer(0)  # Try to fix invalid geometry\\n\",\n",
    "    \"                        return geom.wkt\\n\",\n",
    "    \"                    except:\\n\",\n",
    "    \"                        return None\\n\",\n",
    "    \"\\n\",\n",
    "    \"                gdf['Shape'] = gdf['geometry'].apply(safe_wkt)\\n\",\n",
    "    \"                gdf = gdf.drop('geometry', axis=1)\\n\",\n",
    "    \"                has_geometry = True\\n\",\n",
    "    \"\\n\",\n",
    "    \"                valid_geoms = gdf['Shape'].notna().sum()\\n\",\n",
    "    \"                self.log(f\\\"   ‚úÖ Converted {valid_geoms}/{len(gdf)} geometries to WKT\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Drop existing table\\n\",\n",
    "    \"            self.log(f\\\"   üóëÔ∏è Dropping existing table if exists...\\\")\\n\",\n",
    "    \"            with self.engine.connect() as conn:\\n\",\n",
    "    \"                conn.execute(text(f\\\"IF OBJECT_ID('{layer_name}', 'U') IS NOT NULL DROP TABLE {layer_name}\\\"))\\n\",\n",
    "    \"                conn.commit()\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Write without specifying dtypes - let pandas decide\\n\",\n",
    "    \"            self.log(f\\\"   üíæ Writing {len(gdf)} records to SQL Server...\\\")\\n\",\n",
    "    \"            gdf.to_sql(\\n\",\n",
    "    \"                name=layer_name,\\n\",\n",
    "    \"                con=self.engine,\\n\",\n",
    "    \"                if_exists='replace',\\n\",\n",
    "    \"                index=False,\\n\",\n",
    "    \"                chunksize=self.config['chunk_size']\\n\",\n",
    "    \"                # No dtype parameter - let pandas auto-detect\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Fix geometry column type manually if we have geometry\\n\",\n",
    "    \"            if has_geometry:\\n\",\n",
    "    \"                self.log(f\\\"   üîß Converting Shape column to GEOMETRY type...\\\")\\n\",\n",
    "    \"                try:\\n\",\n",
    "    \"                    with self.engine.connect() as conn:\\n\",\n",
    "    \"                        # Add a new geometry column\\n\",\n",
    "    \"                        conn.execute(text(f\\\"ALTER TABLE {layer_name} ADD Shape_Geom GEOMETRY\\\"))\\n\",\n",
    "    \"\\n\",\n",
    "    \"                        # Update with geometry data\\n\",\n",
    "    \"                        conn.execute(text(f\\\"\\\"\\\"\\n\",\n",
    "    \"                            UPDATE {layer_name}\\n\",\n",
    "    \"                            SET Shape_Geom = geometry::STGeomFromText(Shape, 4326)\\n\",\n",
    "    \"                            WHERE Shape IS NOT NULL AND Shape != ''\\n\",\n",
    "    \"                        \\\"\\\"\\\"))\\n\",\n",
    "    \"\\n\",\n",
    "    \"                        # Drop old text column and rename\\n\",\n",
    "    \"                        conn.execute(text(f\\\"ALTER TABLE {layer_name} DROP COLUMN Shape\\\"))\\n\",\n",
    "    \"                        conn.execute(text(f\\\"EXEC sp_rename '{layer_name}.Shape_Geom', 'Shape', 'COLUMN'\\\"))\\n\",\n",
    "    \"                        conn.commit()\\n\",\n",
    "    \"\\n\",\n",
    "    \"                        # Create spatial index\\n\",\n",
    "    \"                        self.log(f\\\"   üóÇÔ∏è Creating spatial index...\\\")\\n\",\n",
    "    \"                        spatial_index_sql = f\\\"\\\"\\\"\\n\",\n",
    "    \"                        CREATE SPATIAL INDEX SIDX_{layer_name}_Shape\\n\",\n",
    "    \"                        ON {layer_name}(Shape)\\n\",\n",
    "    \"                        USING GEOMETRY_GRID\\n\",\n",
    "    \"                        WITH (BOUNDING_BOX = (-180, -90, 180, 90))\\n\",\n",
    "    \"                        \\\"\\\"\\\"\\n\",\n",
    "    \"                        conn.execute(text(spatial_index_sql))\\n\",\n",
    "    \"                        conn.commit()\\n\",\n",
    "    \"                        self.log(f\\\"   ‚úÖ Spatial index created\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"                except Exception as e:\\n\",\n",
    "    \"                    self.log(f\\\"   ‚ö†Ô∏è Warning: Could not create geometry column or spatial index: {e}\\\", \\\"WARN\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Show column mapping changes\\n\",\n",
    "    \"            changed_cols = [(orig, new) for orig, new in column_mapping.items()\\n\",\n",
    "    \"                           if orig != new and orig != 'geometry']\\n\",\n",
    "    \"            if changed_cols:\\n\",\n",
    "    \"                self.log(f\\\"   üìù Column name changes:\\\")\\n\",\n",
    "    \"                for orig, new in changed_cols[:5]:  # Show first 5\\n\",\n",
    "    \"                    self.log(f\\\"      {orig} ‚Üí {new}\\\")\\n\",\n",
    "    \"                if len(changed_cols) > 5:\\n\",\n",
    "    \"                    self.log(f\\\"      ... and {len(changed_cols) - 5} more\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"            self.log(f\\\"   ‚úÖ Successfully converted {layer_name}\\\")\\n\",\n",
    "    \"            return True\\n\",\n",
    "    \"\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            self.log(f\\\"   ‚ùå Error converting {layer_name}: {e}\\\", \\\"ERROR\\\")\\n\",\n",
    "    \"            import traceback\\n\",\n",
    "    \"            self.log(f\\\"   Details: {traceback.format_exc()}\\\", \\\"ERROR\\\")\\n\",\n",
    "    \"            return False\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def run_conversion(self):\\n\",\n",
    "    \"        \\\"\\\"\\\"Main conversion process\\\"\\\"\\\"\\n\",\n",
    "    \"        self.log(\\\"üöÄ Starting FGDB to SQL Server conversion\\\")\\n\",\n",
    "    \"        self.log(f\\\"üìÅ Source: {self.config['fgdb_path']}\\\")\\n\",\n",
    "    \"        self.log(f\\\"üéØ Target: {self.config['server']} -> {self.config['database']}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Setup connection\\n\",\n",
    "    \"        if not self.setup_connection():\\n\",\n",
    "    \"            return False\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Get layers\\n\",\n",
    "    \"        available_layers = self.get_fgdb_layers()\\n\",\n",
    "    \"        if not available_layers:\\n\",\n",
    "    \"            return False\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Determine which layers to convert\\n\",\n",
    "    \"        if self.config['selected_layers']:\\n\",\n",
    "    \"            layers_to_convert = [l for l in self.config['selected_layers'] if l in available_layers]\\n\",\n",
    "    \"            missing_layers = [l for l in self.config['selected_layers'] if l not in available_layers]\\n\",\n",
    "    \"            if missing_layers:\\n\",\n",
    "    \"                self.log(f\\\"‚ö†Ô∏è Selected layers not found: {missing_layers}\\\", \\\"WARN\\\")\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            layers_to_convert = available_layers\\n\",\n",
    "    \"\\n\",\n",
    "    \"        self.log(f\\\"üìã Converting {len(layers_to_convert)} layers: {', '.join(layers_to_convert)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Convert each layer\\n\",\n",
    "    \"        successful = 0\\n\",\n",
    "    \"        failed = 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"        for i, layer in enumerate(layers_to_convert, 1):\\n\",\n",
    "    \"            self.log(f\\\"\\\\n[{i}/{len(layers_to_convert)}] Processing: {layer}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"            if self.convert_layer(layer):\\n\",\n",
    "    \"                successful += 1\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                failed += 1\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Final summary\\n\",\n",
    "    \"        self.log(f\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"        self.log(f\\\"üìä CONVERSION SUMMARY\\\")\\n\",\n",
    "    \"        self.log(f\\\"=\\\"*60)\\n\",\n",
    "    \"        self.log(f\\\"‚úÖ Successful: {successful}\\\")\\n\",\n",
    "    \"        self.log(f\\\"‚ùå Failed: {failed}\\\")\\n\",\n",
    "    \"        self.log(f\\\"üìã Total: {len(layers_to_convert)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        if successful > 0:\\n\",\n",
    "    \"            self.log(f\\\"\\\\nüéâ Conversion completed!\\\")\\n\",\n",
    "    \"            self.log(f\\\"üîç Test your data with these SQL queries:\\\")\\n\",\n",
    "    \"            self.log(f\\\"   SELECT COUNT(*) FROM {layers_to_convert[0]};\\\")\\n\",\n",
    "    \"            self.log(f\\\"   SELECT TOP 5 * FROM {layers_to_convert[0]};\\\")\\n\",\n",
    "    \"            self.log(f\\\"   SELECT TOP 5 *, Shape.STAsText() AS WKT FROM {layers_to_convert[0]};\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        return failed == 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"def main():\\n\",\n",
    "    \"    \\\"\\\"\\\"Main function\\\"\\\"\\\"\\n\",\n",
    "    \"    print(\\\"=\\\"*60)\\n\",\n",
    "    \"    print(\\\"    FGDB to SQL Server Converter - FIXED VERSION\\\")\\n\",\n",
    "    \"    print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Show configuration\\n\",\n",
    "    \"    print(f\\\"üìã Configuration:\\\")\\n\",\n",
    "    \"    print(f\\\"   Server: {CONFIG['server']}\\\")\\n\",\n",
    "    \"    print(f\\\"   Database: {CONFIG['database']}\\\")\\n\",\n",
    "    \"    print(f\\\"   Username: {CONFIG['username']}\\\")\\n\",\n",
    "    \"    print(f\\\"   FGDB: {CONFIG['fgdb_path']}\\\")\\n\",\n",
    "    \"    print(f\\\"   Chunk size: {CONFIG['chunk_size']}\\\")\\n\",\n",
    "    \"    print(f\\\"   Selected layers: {CONFIG['selected_layers'] or 'All layers'}\\\")\\n\",\n",
    "    \"    print()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Validate FGDB path\\n\",\n",
    "    \"    if not os.path.exists(CONFIG['fgdb_path']):\\n\",\n",
    "    \"        print(f\\\"‚ùå FGDB not found: {CONFIG['fgdb_path']}\\\")\\n\",\n",
    "    \"        print(f\\\"üí° Please update CONFIG['fgdb_path'] to the correct location\\\")\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Create converter and run\\n\",\n",
    "    \"    converter = FGDBConverter(CONFIG)\\n\",\n",
    "    \"    success = converter.run_conversion()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if success:\\n\",\n",
    "    \"        print(f\\\"\\\\nüèÜ All conversions completed successfully!\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(f\\\"\\\\n‚ö†Ô∏è Some conversions failed. Check the log output above.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if __name__ == \\\"__main__\\\":\\n\",\n",
    "    \"    main()\"\n",
    "   ],\n",
    "   \"id\": \"c09453b204d0566c\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"============================================================\\n\",\n",
    "      \"    FGDB to SQL Server Converter - FIXED VERSION\\n\",\n",
    "      \"============================================================\\n\",\n",
    "      \"üìã Configuration:\\n\",\n",
    "      \"   Server: 100.103.17.32,1433\\n\",\n",
    "      \"   Database: SpatialTest\\n\",\n",
    "      \"   Username: dbeaver\\n\",\n",
    "      \"   FGDB: Z:\\\\Users\\\\brendanhall\\\\GitHub\\\\General_Code\\\\ATFS\\\\FGDB to SQL Server Conversion\\\\esri_ref_data.gdb\\\\esri_ref_data.gdb\\n\",\n",
    "      \"   Chunk size: 1000\\n\",\n",
    "      \"   Selected layers: All layers\\n\",\n",
    "      \"\\n\",\n",
    "      \"[INFO] üöÄ Starting FGDB to SQL Server conversion\\n\",\n",
    "      \"[INFO] üìÅ Source: Z:\\\\Users\\\\brendanhall\\\\GitHub\\\\General_Code\\\\ATFS\\\\FGDB to SQL Server Conversion\\\\esri_ref_data.gdb\\\\esri_ref_data.gdb\\n\",\n",
    "      \"[INFO] üéØ Target: 100.103.17.32,1433 -> SpatialTest\\n\",\n",
    "      \"[INFO] Setting up SQL Server connection...\\n\",\n",
    "      \"[INFO] ‚úÖ Connected to SQL Server\\n\",\n",
    "      \"[INFO]    Database: SpatialTest\\n\",\n",
    "      \"[INFO]    Version: Microsoft SQL Server 2022 (RTM-GDR) (KB5046861) - ...\\n\",\n",
    "      \"[INFO] Reading FGDB: Z:\\\\Users\\\\brendanhall\\\\GitHub\\\\General_Code\\\\ATFS\\\\FGDB to SQL Server Conversion\\\\esri_ref_data.gdb\\\\esri_ref_data.gdb\\n\",\n",
    "      \"[INFO] ‚úÖ Found 4 layers: states, fedlandp, park_dtl, dtl_st\\n\",\n",
    "      \"[INFO] üìã Converting 4 layers: states, fedlandp, park_dtl, dtl_st\\n\",\n",
    "      \"[INFO] \\n\",\n",
    "      \"[1/4] Processing: states\\n\",\n",
    "      \"[INFO] \\n\",\n",
    "      \"üîÑ Converting layer: states\\n\",\n",
    "      \"[INFO]    üìä Processing 51 features\\n\",\n",
    "      \"[INFO]    üó∫Ô∏è Geometry types: {'MultiPolygon': np.int64(51)}\\n\",\n",
    "      \"[INFO]    üîß Converting geometry to WKT...\\n\",\n",
    "      \"[INFO]    ‚úÖ Converted 51/51 geometries to WKT\\n\",\n",
    "      \"[INFO]    üóëÔ∏è Dropping existing table if exists...\\n\",\n",
    "      \"[INFO]    üíæ Writing 51 records to SQL Server...\\n\",\n",
    "      \"[INFO]    üîß Converting Shape column to GEOMETRY type...\\n\",\n",
    "      \"[INFO]    üóÇÔ∏è Creating spatial index...\\n\",\n",
    "      \"[WARN]    ‚ö†Ô∏è Warning: Could not create geometry column or spatial index: (pyodbc.ProgrammingError) ('42000', \\\"[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Table 'states' does not have a clustered primary key as required by the spatial index. Make sure that the primary key column exists on the table before creating a spatial index. (12008) (SQLExecDirectW)\\\")\\n\",\n",
    "      \"[SQL: \\n\",\n",
    "      \"                        CREATE SPATIAL INDEX SIDX_states_Shape\\n\",\n",
    "      \"                        ON states(Shape)\\n\",\n",
    "      \"                        USING GEOMETRY_GRID\\n\",\n",
    "      \"                        WITH (BOUNDING_BOX = (-180, -90, 180, 90))\\n\",\n",
    "      \"                        ]\\n\",\n",
    "      \"(Background on this error at: https://sqlalche.me/e/20/f405)\\n\",\n",
    "      \"[INFO]    ‚úÖ Successfully converted states\\n\",\n",
    "      \"[INFO] \\n\",\n",
    "      \"[2/4] Processing: fedlandp\\n\",\n",
    "      \"[INFO] \\n\",\n",
    "      \"üîÑ Converting layer: fedlandp\\n\",\n",
    "      \"[INFO]    üìä Processing 3687 features\\n\",\n",
    "      \"[INFO]    üó∫Ô∏è Geometry types: {'MultiPolygon': np.int64(3687)}\\n\",\n",
    "      \"[INFO]    üîß Converting geometry to WKT...\\n\",\n",
    "      \"[INFO]    ‚úÖ Converted 3687/3687 geometries to WKT\\n\",\n",
    "      \"[INFO]    üóëÔ∏è Dropping existing table if exists...\\n\",\n",
    "      \"[INFO]    üíæ Writing 3687 records to SQL Server...\\n\",\n",
    "      \"[INFO]    üîß Converting Shape column to GEOMETRY type...\\n\",\n",
    "      \"[INFO]    üóÇÔ∏è Creating spatial index...\\n\",\n",
    "      \"[WARN]    ‚ö†Ô∏è Warning: Could not create geometry column or spatial index: (pyodbc.ProgrammingError) ('42000', \\\"[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Table 'fedlandp' does not have a clustered primary key as required by the spatial index. Make sure that the primary key column exists on the table before creating a spatial index. (12008) (SQLExecDirectW)\\\")\\n\",\n",
    "      \"[SQL: \\n\",\n",
    "      \"                        CREATE SPATIAL INDEX SIDX_fedlandp_Shape\\n\",\n",
    "      \"                        ON fedlandp(Shape)\\n\",\n",
    "      \"                        USING GEOMETRY_GRID\\n\",\n",
    "      \"                        WITH (BOUNDING_BOX = (-180, -90, 180, 90))\\n\",\n",
    "      \"                        ]\\n\",\n",
    "      \"(Background on this error at: https://sqlalche.me/e/20/f405)\\n\",\n",
    "      \"[INFO]    ‚úÖ Successfully converted fedlandp\\n\",\n",
    "      \"[INFO] \\n\",\n",
    "      \"[3/4] Processing: park_dtl\\n\",\n",
    "      \"[INFO] \\n\",\n",
    "      \"üîÑ Converting layer: park_dtl\\n\",\n",
    "      \"[INFO]    üìä Processing 26307 features\\n\",\n",
    "      \"[INFO]    üó∫Ô∏è Geometry types: {'MultiPolygon': np.int64(26307)}\\n\",\n",
    "      \"[INFO]    üîß Converting geometry to WKT...\\n\",\n",
    "      \"[INFO]    ‚úÖ Converted 26307/26307 geometries to WKT\\n\",\n",
    "      \"[INFO]    üóëÔ∏è Dropping existing table if exists...\\n\",\n",
    "      \"[INFO]    üíæ Writing 26307 records to SQL Server...\\n\",\n",
    "      \"[INFO]    üîß Converting Shape column to GEOMETRY type...\\n\",\n",
    "      \"[INFO]    üóÇÔ∏è Creating spatial index...\\n\",\n",
    "      \"[WARN]    ‚ö†Ô∏è Warning: Could not create geometry column or spatial index: (pyodbc.ProgrammingError) ('42000', \\\"[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Table 'park_dtl' does not have a clustered primary key as required by the spatial index. Make sure that the primary key column exists on the table before creating a spatial index. (12008) (SQLExecDirectW)\\\")\\n\",\n",
    "      \"[SQL: \\n\",\n",
    "      \"                        CREATE SPATIAL INDEX SIDX_park_dtl_Shape\\n\",\n",
    "      \"                        ON park_dtl(Shape)\\n\",\n",
    "      \"                        USING GEOMETRY_GRID\\n\",\n",
    "      \"                        WITH (BOUNDING_BOX = (-180, -90, 180, 90))\\n\",\n",
    "      \"                        ]\\n\",\n",
    "      \"(Background on this error at: https://sqlalche.me/e/20/f405)\\n\",\n",
    "      \"[INFO]    ‚úÖ Successfully converted park_dtl\\n\",\n",
    "      \"[INFO] \\n\",\n",
    "      \"[4/4] Processing: dtl_st\\n\",\n",
    "      \"[INFO] \\n\",\n",
    "      \"üîÑ Converting layer: dtl_st\\n\",\n",
    "      \"[INFO]    üìä Processing 51 features\\n\",\n",
    "      \"[INFO]    üó∫Ô∏è Geometry types: {'MultiPolygon': np.int64(51)}\\n\",\n",
    "      \"[INFO]    üîß Converting geometry to WKT...\\n\",\n",
    "      \"[INFO]    ‚úÖ Converted 51/51 geometries to WKT\\n\",\n",
    "      \"[INFO]    üóëÔ∏è Dropping existing table if exists...\\n\",\n",
    "      \"[INFO]    üíæ Writing 51 records to SQL Server...\\n\",\n",
    "      \"[INFO]    üîß Converting Shape column to GEOMETRY type...\\n\",\n",
    "      \"[INFO]    üóÇÔ∏è Creating spatial index...\\n\",\n",
    "      \"[WARN]    ‚ö†Ô∏è Warning: Could not create geometry column or spatial index: (pyodbc.ProgrammingError) ('42000', \\\"[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Table 'dtl_st' does not have a clustered primary key as required by the spatial index. Make sure that the primary key column exists on the table before creating a spatial index. (12008) (SQLExecDirectW)\\\")\\n\",\n",
    "      \"[SQL: \\n\",\n",
    "      \"                        CREATE SPATIAL INDEX SIDX_dtl_st_Shape\\n\",\n",
    "      \"                        ON dtl_st(Shape)\\n\",\n",
    "      \"                        USING GEOMETRY_GRID\\n\",\n",
    "      \"                        WITH (BOUNDING_BOX = (-180, -90, 180, 90))\\n\",\n",
    "      \"                        ]\\n\",\n",
    "      \"(Background on this error at: https://sqlalche.me/e/20/f405)\\n\",\n",
    "      \"[INFO]    ‚úÖ Successfully converted dtl_st\\n\",\n",
    "      \"[INFO] \\n\",\n",
    "      \"============================================================\\n\",\n",
    "      \"[INFO] üìä CONVERSION SUMMARY\\n\",\n",
    "      \"[INFO] ============================================================\\n\",\n",
    "      \"[INFO] ‚úÖ Successful: 4\\n\",\n",
    "      \"[INFO] ‚ùå Failed: 0\\n\",\n",
    "      \"[INFO] üìã Total: 4\\n\",\n",
    "      \"[INFO] \\n\",\n",
    "      \"üéâ Conversion completed!\\n\",\n",
    "      \"[INFO] üîç Test your data with these SQL queries:\\n\",\n",
    "      \"[INFO]    SELECT COUNT(*) FROM states;\\n\",\n",
    "      \"[INFO]    SELECT TOP 5 * FROM states;\\n\",\n",
    "      \"[INFO]    SELECT TOP 5 *, Shape.STAsText() AS WKT FROM states;\\n\",\n",
    "      \"\\n\",\n",
    "      \"üèÜ All conversions completed successfully!\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 10\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 2\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython2\",\n",
    "   \"version\": \"2.7.6\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "4e4e2428bfaff67d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
